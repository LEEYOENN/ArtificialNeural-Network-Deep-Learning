{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEEYOENN/ArtificialNeural-Network-Deep-Learning/blob/main/Peaple_emotion_multiful_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Haf1jD0NisR2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential, Input\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle, cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnyAFuGIaefl",
        "outputId": "32c01deb-7c32-424d-dfa2-201a2ae81a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['x', 'y']\n"
          ]
        }
      ],
      "source": [
        "data = np.load(\"/content/drive/MyDrive/DeepLearning/train.npz\")\n",
        "print(data.files)\n",
        "['x', 'y']\n",
        "x_train = data['x']\n",
        "y_train = data['y']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKmfem-D1Q-H",
        "outputId": "00821279-6acf-457d-ef6a-7ae68e3d808b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습셋 이미지 수: 29540\n"
          ]
        }
      ],
      "source": [
        "# x_train, x_test, y_train, y_test = train_test_split(x_train,y_train,\n",
        "#                                                     test_size=0.2,\n",
        "#                                                     random_state=42)\n",
        "##이미지셋 개수 확인\n",
        "print(\"학습셋 이미지 수: %d\" % (x_train.shape[0]))\n",
        "#print(\"테스트셋 이미지 수: %d\" % (x_test.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLZ9Ytl29cuG",
        "outputId": "66865187-2a06-495f-845b-41abe154fea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 3 0 ... 3 3 3]\n"
          ]
        }
      ],
      "source": [
        "print(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "-XTe1zix2W7H",
        "outputId": "cd171fcb-fe42-4a3a-db95-07296ddcd662"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "##X_TRAIN의 10000번째 이미지보기\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(x_train[10000], cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo77tBws2wvs",
        "outputId": "8df8ff4c-de67-4bd2-d2dc-ded1fc9fc837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18016714512512011112415318019520221322222823223823924123924022721421220518616517099 51 60 62 67 64 39 56 28 19 19 19 25 23 16 43 53 71 53 72 137\n",
            "17616113112111611213517219119920622122723423924324124224324223522522021620218818314956 49 54 55 63 46 38 39 16 19 15 20 27 17 20 48 53 66 48 100\n",
            "16913911811811912515018019620421622422623523924224224124224323823022622621620119117510034 49 52 55 54 35 36 24 15 18 14 22 26 14 29 47 57 55 65 \n",
            "15712011512212813416418919620921722222923623924024124124124123823322422622521320118213667 31 50 50 51 38 31 33 17 15 16 17 27 19 15 39 47 60 52 \n",
            "13511011311611814216918519621022323123623823924024024124023823623522722822922120919915410242 29 53 54 41 27 30 27 12 17 14 22 26 15 20 43 43 58 \n",
            "11810510610210913116318620521722322723423924024023923923823423323222622722622321520319011973 28 35 55 43 27 29 32 19 11 17 15 26 21 12 30 47 44 \n",
            "10810198 92 95 12717519921522322623123523824024023823723623123523422622222022221621120817189 56 27 45 47 30 25 23 24 13 14 13 19 26 16 16 45 43 \n",
            "10093 90 82 95 15018920921622423223323623723924023923923623123123022621822022421821621320513966 36 24 45 29 17 19 25 21 10 16 17 23 26 16 28 52 \n",
            "90 82 88 76 10716919620821822823223523723723823924023823522923022822522722122321821722221018810451 24 28 39 19 15 21 24 15 11 18 15 26 23 16 43 \n",
            "80 69 79 66 11517219120221322723423523723823823723923823523323422922722722722822322122021218914769 40 21 36 28 11 16 23 21 12 14 14 20 28 18 26 \n",
            "69 61 71 63 11416818619921622823323423723923823523723523823623223122121723023122922622320517415511247 32 28 35 16 11 19 22 17 10 15 15 26 26 20 \n",
            "66 54 64 67 11516518820422022923123523623823923423323623123222722520320722622322621421218916515817288 34 27 31 24 12 13 22 21 12 12 13 18 28 22 \n",
            "64 48 56 74 12017720521522423023223423523823823223123323123022122319920022921721920820820218317819316556 37 26 31 16 12 17 24 17 9  13 11 27 27 \n",
            "55 43 57 77 13119821222222522923223523123023624024324323522621721919919823021521120719518717816015514178 42 31 30 26 12 10 27 22 14 12 12 17 32 \n",
            "53 44 59 76 15721221422222422522520318919519119317514513016318120920119922921119817210876 62 55 51 50 57 54 38 27 31 16 10 18 25 20 11 14 11 28 \n",
            "53 48 58 75 18721421721819819017416417115712292 71 60 65 90 12419220620522820415710168 49 35 31 32 43 62 74 52 33 31 24 12 12 22 22 15 12 14 17 \n",
            "54 55 51 86 20421621619218319320020920517912376 65 76 98 11412918221222222519510761 72 57 56 56 39 17 22 28 42 45 33 33 15 14 17 20 23 12 17 15 \n",
            "56 63 46 11021221621621221821819918415311567 42 51 77 10414415918121923122818378 54 71 10811910885 65 13 34 37 44 43 38 29 14 18 18 27 24 15 19 \n",
            "64 66 36 13221921721921721118015210962 45 78 11 81 12512515717218521823223019278 48 10513612521412759 30 80 86 35 40 43 40 23 17 19 19 32 19 19 \n",
            "69 68 30 15022221921621119315583 83 17010857 53 13619415218121320421923623120496 72 14013317523216774 87 10311070 33 43 49 36 19 20 16 26 27 16 \n",
            "75 64 30 16522122122121620616211917223118813013317819118420021720920922021320013397 15218619018918714712312311189 47 49 66 55 32 22 21 23 32 23 \n",
            "83 60 32 16821922322922922822219317718719117917518017418220522021721421921720416210514017817918217416013110792 79 65 83 92 76 50 30 24 22 30 30 \n",
            "86 64 28 16621522123023323323221819718217817717117518319921923222722423522921118011713117418118618317014912310610511913812810070 42 31 22 27 32 \n",
            "86 66 24 15921421722823123323523421820020620319920120421323022522222423522821017713412215917818019119118317116616517117115212592 56 39 15 18 25 \n",
            "81 68 19 14220821222723023423523121721422922822321221723123422722722823522921017713711914917918118919519219119018518117816313811576 46 23 4  15 \n",
            "74 68 14 11320120622322922922221521622623122622222323123322822222221823023021118013511714518418718619219919718918317917316214612710355 32 6  9  \n",
            "78 68 13 79 19520521822421521121922823423422822722623122321220821020921421620818714511013818419719619018919318717817216715814813311758 20 16 6  \n",
            "83 70 16 44 18020521521520521622622723023223122922922221521120920521021120720019616210512018019820019919018618717516816415414413212450 5  9  6  \n",
            "71 74 21 16 14520521121220221622222222722922822822521121020920420621121321520019217312910716819520020319218218517416515614313613311934 1  2  5  \n",
            "65 73 22 2  10319920720919921221622222322722622621720620920520320721021921920218616314511214118919620119018018017215914813813113210718 5  3  4  \n",
            "61 69 21 2  63 18820520519921121621621822422422521220620420320220720620320219016414213210510617619419218518117917015414113212713293 8  11 5  4  \n",
            "57 72 24 9  40 16720220419620921221522321921822320920020320518815115019618816813271 91 79 74 15818718918217517916714913512812913380 15 6  2  6  \n",
            "54 71 24 13 37 14820119919320821421721721721822021020020821218514015118417014289 40 60 65 90 15718519118017217516114313112713013364 11 7  1  7  \n",
            "52 64 25 14 13 11920119719320821421521421421621621720320921120319420519316012496 78 82 10313616618418917917217415313712912813213244 0  2  1  7  \n",
            "50 56 28 5  0  83 19919419020721221321421321522022321820720520520620719417018817513113214516417618218617517016715013512913013612627 0  1  2  8  \n",
            "54 53 28 8  0  52 19119518920621121321421621521922423022320720320320719420423121618416416517417818118317016316314713513213514111512 0  0  2  9  \n",
            "54 51 33 12 1  24 17620018720821121021021321621822322522922822722622021321821418917817517517517517417616515915914513613413814599 3  1  0  3  10 \n",
            "58 49 35 14 10 4  14920218620721421020921421421621321622222521719016315616212811312313115817217317017316115515614413713613814675 0  1  0  5  11 \n",
            "53 50 36 11 11 0  10720218520821021221221421120219618019618013212413613312611010510194 10412915917316915515115114414013813914145 0  2  1  7  15 \n",
            "51 49 35 14 5  0  55 19118420721421421521420018916313213110013217619820318118016614513289 76 10917116715114615014414113914412215 1  1  2  8  20 \n",
            "51 49 38 17 6  2  13 15718618920520720820218517915313411010614816218621018219117313912379 12314416915914014414814114014114680 0  3  1  2  10 25 \n",
            "43 55 39 23 6  5  0  92 19818018418318718518117718218616816416716216616916516615215014113314815015014214114614113613814013331 0  3  1  4  14 26 \n",
            "34 57 43 24 9  4  2  20 16920219519719919719419720220419018218118818517417718516814913312312813314714614313813213213113881 1  2  1  2  6  16 28 \n",
            "26 48 50 24 12 7  6  0  76 19820120821120920520621321921319518518017917417216614612311011411912613713713112712712712911418 1  1  1  2  9  19 29 \n",
            "26 35 48 31 10 12 5  8  10 12819217718218419020420118618718517716515313312512111010111111411911411211411411812512212747 0  3  2  2  5  13 22 32 \n",
            "24 29 47 37 10 11 10 8  11 50 16517217617717318819517617717616815514812411311611510510511510710010811211311712412983 3  2  2  2  2  8  14 27 46 \n",
            "23 27 35 45 17 5  13 10 12 32 13818419420218218120520420220118215416615914515314412510911810610812412712712211989 23 3  1  1  2  3  12 16 33 55 \n",
            "24 24 31 47 21 5  8  12 16 34 14018117918117418521119718618517917520919517919017414312413411711712612311912094 32 13 5  2  2  2  5  15 17 36 56 \n"
          ]
        }
      ],
      "source": [
        "##이미지 데이터셋 숫자 살펴보기\n",
        "import sys\n",
        "for row in x_train[0]:\n",
        "  for pixel in row:\n",
        "    sys.stdout.write(\"%-3d\" % pixel)\n",
        "  sys.stdout.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz0KoAZd4w3k"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 48, 48, 1).astype(\"float64\") / 255\n",
        "#x_test = x_test.reshape(x_test.shape[0], 2304).astype(\"float64\") / 255\n",
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaj46bTX6qR5"
      },
      "outputs": [],
      "source": [
        "##0번째 레이블의 클래스확인 : 3\n",
        "#print(\"Class: %d\" % (y_train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-cuBkn_8zNE"
      },
      "outputs": [],
      "source": [
        "y_train = keras.utils.to_categorical(y_train, 5)\n",
        "#y_test = keras.utils.to_categorical(y_test, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jevLqa_w9Qe8",
        "outputId": "1c2661ee-bc91-478e-e9a4-d66f437738c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 1.]\n"
          ]
        }
      ],
      "source": [
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEMJPqk6ae6E",
        "outputId": "bbf7a8c5-f10a-409f-e5c9-bb4dd9d10df2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 45, 45, 32)        544       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 42, 42, 64)        32832     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 21, 21, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 21, 21, 64)        0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 28224)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1024)              28902400  \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29593189 (112.89 MB)\n",
            "Trainable params: 29593189 (112.89 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def build_model() :\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=(48, 48, 1)))\n",
        "  model.add(Conv2D(filters=32, kernel_size=(4, 4), activation=\"relu\"))\n",
        "  model.add(Conv2D(64, (4,4), activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(rate=0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation=\"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(512, activation=\"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(256, activation=\"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(5, activation=\"softmax\"))\n",
        "  return model\n",
        "model = build_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYaq8iUOr0QV"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itJRMXTOthWU"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "#모델 최적화를 위한 설정구간\n",
        "modelpath = \"facial_model.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor=\"val_los\", verbose=0, save_best_model=True)\n",
        "early_stopping_callback = EarlyStopping(monitor=\"val_loss\", patience=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMHSzjhgwfvX",
        "outputId": "de8dcf64-3eb4-47c1-ad09-94ef5402c0ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "507/507 [==============================] - 18s 32ms/step - loss: 1.3375 - accuracy: 0.4211 - val_loss: 1.0220 - val_accuracy: 0.5872\n",
            "Epoch 2/2000\n",
            "507/507 [==============================] - 16s 31ms/step - loss: 0.9988 - accuracy: 0.5946 - val_loss: 0.8834 - val_accuracy: 0.6471\n",
            "Epoch 3/2000\n",
            "507/507 [==============================] - 16s 32ms/step - loss: 0.8393 - accuracy: 0.6623 - val_loss: 0.7933 - val_accuracy: 0.6801\n",
            "Epoch 4/2000\n",
            "507/507 [==============================] - 14s 27ms/step - loss: 0.7157 - accuracy: 0.7181 - val_loss: 0.7258 - val_accuracy: 0.7079\n",
            "Epoch 5/2000\n",
            "507/507 [==============================] - 15s 30ms/step - loss: 0.6186 - accuracy: 0.7589 - val_loss: 0.7591 - val_accuracy: 0.7014\n",
            "Epoch 6/2000\n",
            "507/507 [==============================] - 15s 29ms/step - loss: 0.5104 - accuracy: 0.8026 - val_loss: 0.7301 - val_accuracy: 0.7258\n",
            "Epoch 7/2000\n",
            "507/507 [==============================] - 16s 31ms/step - loss: 0.4158 - accuracy: 0.8404 - val_loss: 0.7604 - val_accuracy: 0.7238\n",
            "Epoch 8/2000\n",
            "507/507 [==============================] - 12s 24ms/step - loss: 0.3476 - accuracy: 0.8746 - val_loss: 0.7680 - val_accuracy: 0.7326\n",
            "Epoch 9/2000\n",
            "507/507 [==============================] - 15s 29ms/step - loss: 0.2776 - accuracy: 0.9005 - val_loss: 0.8245 - val_accuracy: 0.7326\n",
            "Epoch 10/2000\n",
            "507/507 [==============================] - 12s 23ms/step - loss: 0.2296 - accuracy: 0.9180 - val_loss: 0.8766 - val_accuracy: 0.7336\n",
            "Epoch 11/2000\n",
            "507/507 [==============================] - 12s 23ms/step - loss: 0.2016 - accuracy: 0.9294 - val_loss: 0.9487 - val_accuracy: 0.7312\n",
            "Epoch 12/2000\n",
            "507/507 [==============================] - 16s 31ms/step - loss: 0.1796 - accuracy: 0.9390 - val_loss: 0.9184 - val_accuracy: 0.7332\n",
            "Epoch 13/2000\n",
            "507/507 [==============================] - 17s 33ms/step - loss: 0.1715 - accuracy: 0.9411 - val_loss: 0.9719 - val_accuracy: 0.7287\n",
            "Epoch 14/2000\n",
            "507/507 [==============================] - 15s 30ms/step - loss: 0.1447 - accuracy: 0.9514 - val_loss: 1.0063 - val_accuracy: 0.7309\n",
            "185/185 - 1s - loss: 0.9878 - accuracy: 0.7302 - 772ms/epoch - 4ms/step\n",
            "185/185 [==============================] - 1s 5ms/step - loss: 0.9878 - accuracy: 0.7302\n",
            "Test Accuracy: 73.02%\n",
            "Epoch 1/2000\n",
            "507/507 [==============================] - 16s 31ms/step - loss: 0.3735 - accuracy: 0.8845 - val_loss: 0.6797 - val_accuracy: 0.7382\n",
            "Epoch 2/2000\n",
            "507/507 [==============================] - 13s 25ms/step - loss: 0.2726 - accuracy: 0.9136 - val_loss: 0.7240 - val_accuracy: 0.7370\n",
            "Epoch 3/2000\n",
            "507/507 [==============================] - 14s 27ms/step - loss: 0.2100 - accuracy: 0.9302 - val_loss: 0.7881 - val_accuracy: 0.7461\n",
            "Epoch 4/2000\n",
            "507/507 [==============================] - 16s 31ms/step - loss: 0.1699 - accuracy: 0.9453 - val_loss: 0.8916 - val_accuracy: 0.7412\n",
            "Epoch 5/2000\n",
            "507/507 [==============================] - 16s 32ms/step - loss: 0.1509 - accuracy: 0.9529 - val_loss: 0.8579 - val_accuracy: 0.7398\n",
            "Epoch 6/2000\n",
            "507/507 [==============================] - 14s 28ms/step - loss: 0.1368 - accuracy: 0.9576 - val_loss: 0.9076 - val_accuracy: 0.7442\n",
            "Epoch 7/2000\n",
            "507/507 [==============================] - 15s 30ms/step - loss: 0.1278 - accuracy: 0.9615 - val_loss: 0.8804 - val_accuracy: 0.7441\n",
            "Epoch 8/2000\n",
            "507/507 [==============================] - 15s 30ms/step - loss: 0.1096 - accuracy: 0.9642 - val_loss: 1.0132 - val_accuracy: 0.7385\n",
            "Epoch 9/2000\n",
            "507/507 [==============================] - 15s 30ms/step - loss: 0.1142 - accuracy: 0.9621 - val_loss: 0.9618 - val_accuracy: 0.7476\n",
            "Epoch 10/2000\n",
            "507/507 [==============================] - 12s 25ms/step - loss: 0.1003 - accuracy: 0.9705 - val_loss: 1.0368 - val_accuracy: 0.7464\n",
            "Epoch 11/2000\n",
            "507/507 [==============================] - 12s 25ms/step - loss: 0.1056 - accuracy: 0.9658 - val_loss: 0.9524 - val_accuracy: 0.7478\n",
            "185/185 - 1s - loss: 0.3283 - accuracy: 0.9132 - 766ms/epoch - 4ms/step\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.3283 - accuracy: 0.9132\n",
            "Test Accuracy: 91.32%\n",
            "Epoch 1/2000\n",
            "507/507 [==============================] - 16s 31ms/step - loss: 0.1630 - accuracy: 0.9502 - val_loss: 0.8533 - val_accuracy: 0.7507\n",
            "Epoch 2/2000\n",
            "507/507 [==============================] - 15s 30ms/step - loss: 0.1203 - accuracy: 0.9618 - val_loss: 0.9349 - val_accuracy: 0.7451\n",
            "Epoch 3/2000\n",
            "507/507 [==============================] - 13s 25ms/step - loss: 0.0996 - accuracy: 0.9681 - val_loss: 0.9408 - val_accuracy: 0.7556\n",
            "Epoch 4/2000\n",
            "507/507 [==============================] - 15s 29ms/step - loss: 0.1007 - accuracy: 0.9694 - val_loss: 1.0348 - val_accuracy: 0.7468\n",
            "Epoch 5/2000\n",
            "507/507 [==============================] - 16s 31ms/step - loss: 0.0941 - accuracy: 0.9705 - val_loss: 0.9792 - val_accuracy: 0.7481\n",
            "Epoch 6/2000\n",
            "507/507 [==============================] - 16s 31ms/step - loss: 0.0868 - accuracy: 0.9719 - val_loss: 0.9632 - val_accuracy: 0.7471\n",
            "Epoch 7/2000\n",
            "507/507 [==============================] - 14s 27ms/step - loss: 0.0858 - accuracy: 0.9730 - val_loss: 1.0050 - val_accuracy: 0.7431\n",
            "Epoch 8/2000\n",
            "507/507 [==============================] - 15s 30ms/step - loss: 0.0744 - accuracy: 0.9768 - val_loss: 1.0074 - val_accuracy: 0.7558\n",
            "Epoch 9/2000\n",
            "507/507 [==============================] - 16s 32ms/step - loss: 0.0816 - accuracy: 0.9755 - val_loss: 1.0053 - val_accuracy: 0.7486\n",
            "Epoch 10/2000\n",
            "507/507 [==============================] - 15s 30ms/step - loss: 0.0753 - accuracy: 0.9779 - val_loss: 1.1342 - val_accuracy: 0.7439\n",
            "Epoch 11/2000\n",
            "507/507 [==============================] - 18s 35ms/step - loss: 0.0668 - accuracy: 0.9784 - val_loss: 1.1123 - val_accuracy: 0.7441\n",
            "185/185 - 1s - loss: 0.3131 - accuracy: 0.9281 - 958ms/epoch - 5ms/step\n",
            "185/185 [==============================] - 1s 5ms/step - loss: 0.3131 - accuracy: 0.9281\n",
            "Test Accuracy: 92.81%\n",
            "Epoch 1/2000\n",
            "507/507 [==============================] - 16s 32ms/step - loss: 0.0956 - accuracy: 0.9711 - val_loss: 0.9576 - val_accuracy: 0.7525\n",
            "Epoch 2/2000\n",
            "507/507 [==============================] - 16s 32ms/step - loss: 0.0856 - accuracy: 0.9737 - val_loss: 1.0662 - val_accuracy: 0.7495\n",
            "Epoch 3/2000\n",
            "507/507 [==============================] - 16s 32ms/step - loss: 0.0838 - accuracy: 0.9749 - val_loss: 1.1216 - val_accuracy: 0.7495\n",
            "Epoch 4/2000\n",
            "507/507 [==============================] - 16s 32ms/step - loss: 0.0808 - accuracy: 0.9759 - val_loss: 1.0706 - val_accuracy: 0.7578\n",
            "Epoch 5/2000\n",
            "507/507 [==============================] - 14s 27ms/step - loss: 0.0763 - accuracy: 0.9762 - val_loss: 1.0926 - val_accuracy: 0.7537\n",
            "Epoch 6/2000\n",
            "507/507 [==============================] - 14s 28ms/step - loss: 0.0732 - accuracy: 0.9782 - val_loss: 1.1523 - val_accuracy: 0.7534\n",
            "Epoch 7/2000\n",
            "507/507 [==============================] - 20s 39ms/step - loss: 0.0691 - accuracy: 0.9792 - val_loss: 1.1766 - val_accuracy: 0.7490\n",
            "Epoch 8/2000\n",
            "507/507 [==============================] - 14s 27ms/step - loss: 0.0758 - accuracy: 0.9781 - val_loss: 1.0147 - val_accuracy: 0.7536\n",
            "Epoch 9/2000\n",
            "507/507 [==============================] - 17s 33ms/step - loss: 0.0589 - accuracy: 0.9812 - val_loss: 1.1899 - val_accuracy: 0.7497\n",
            "Epoch 10/2000\n",
            "507/507 [==============================] - 13s 26ms/step - loss: 0.0607 - accuracy: 0.9822 - val_loss: 1.1834 - val_accuracy: 0.7508\n",
            "Epoch 11/2000\n",
            "507/507 [==============================] - 20s 40ms/step - loss: 0.0588 - accuracy: 0.9821 - val_loss: 1.1272 - val_accuracy: 0.7500\n",
            "185/185 - 1s - loss: 0.2857 - accuracy: 0.9358 - 745ms/epoch - 4ms/step\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.2857 - accuracy: 0.9358\n",
            "Test Accuracy: 93.58%\n",
            "Epoch 1/2000\n",
            "507/507 [==============================] - 15s 30ms/step - loss: 0.0785 - accuracy: 0.9766 - val_loss: 1.1282 - val_accuracy: 0.7481\n",
            "Epoch 2/2000\n",
            "507/507 [==============================] - 15s 30ms/step - loss: 0.0801 - accuracy: 0.9775 - val_loss: 1.0991 - val_accuracy: 0.7480\n",
            "Epoch 3/2000\n",
            "507/507 [==============================] - 11s 22ms/step - loss: 0.0665 - accuracy: 0.9806 - val_loss: 1.1698 - val_accuracy: 0.7470\n",
            "Epoch 4/2000\n",
            "507/507 [==============================] - 20s 40ms/step - loss: 0.0614 - accuracy: 0.9814 - val_loss: 1.0923 - val_accuracy: 0.7498\n",
            "Epoch 5/2000\n",
            "507/507 [==============================] - 16s 31ms/step - loss: 0.0610 - accuracy: 0.9809 - val_loss: 1.1903 - val_accuracy: 0.7515\n",
            "Epoch 6/2000\n",
            "507/507 [==============================] - 15s 29ms/step - loss: 0.0616 - accuracy: 0.9809 - val_loss: 1.1573 - val_accuracy: 0.7497\n",
            "Epoch 7/2000\n",
            "507/507 [==============================] - 12s 23ms/step - loss: 0.0565 - accuracy: 0.9836 - val_loss: 1.2624 - val_accuracy: 0.7476\n",
            "Epoch 8/2000\n",
            "507/507 [==============================] - 16s 31ms/step - loss: 0.0612 - accuracy: 0.9827 - val_loss: 1.2266 - val_accuracy: 0.7571\n",
            "Epoch 9/2000\n",
            "507/507 [==============================] - 15s 29ms/step - loss: 0.0559 - accuracy: 0.9830 - val_loss: 1.2082 - val_accuracy: 0.7437\n",
            "Epoch 10/2000\n",
            "507/507 [==============================] - 18s 35ms/step - loss: 0.0550 - accuracy: 0.9842 - val_loss: 1.1370 - val_accuracy: 0.7520\n",
            "Epoch 11/2000\n",
            "507/507 [==============================] - 18s 36ms/step - loss: 0.0479 - accuracy: 0.9871 - val_loss: 1.2972 - val_accuracy: 0.7554\n",
            "Epoch 12/2000\n",
            "507/507 [==============================] - 16s 32ms/step - loss: 0.0637 - accuracy: 0.9820 - val_loss: 1.1266 - val_accuracy: 0.7444\n",
            "Epoch 13/2000\n",
            "507/507 [==============================] - 20s 39ms/step - loss: 0.0501 - accuracy: 0.9863 - val_loss: 1.2113 - val_accuracy: 0.7508\n",
            "Epoch 14/2000\n",
            "507/507 [==============================] - 15s 29ms/step - loss: 0.0537 - accuracy: 0.9839 - val_loss: 1.1586 - val_accuracy: 0.7458\n",
            "185/185 - 1s - loss: 0.3000 - accuracy: 0.9365 - 761ms/epoch - 4ms/step\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.3000 - accuracy: 0.9365\n",
            "Test Accuracy: 93.65%\n",
            "88.87609958648682\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "k = 5\n",
        "cv = KFold(n_splits = k, shuffle=True)\n",
        "acc_list = []\n",
        "for train_index, test_index in cv.split(x_train) :\n",
        "  x_train1 = x_train[train_index,:]\n",
        "  x_test1 = x_train[test_index,:]\n",
        "\n",
        "  y_train1 = y_train[train_index]\n",
        "  y_test1 = y_train[test_index]\n",
        "\n",
        "\n",
        "  history = model.fit(x_train1, y_train1, epochs=2000, batch_size=35, validation_split=0.25, verbose=1, callbacks=[early_stopping_callback, checkpointer])\n",
        "\n",
        "  acc_list.append(100 * model.evaluate(x_test1, y_test1, verbose=2)[1])\n",
        "  score = model.evaluate(x_test1, y_test1)\n",
        "  print(\"Test Accuracy: %.2f%%\" % (score[1] * 100))\n",
        "print(sum(acc_list)/5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmxBfWVtAhUZ"
      },
      "outputs": [],
      "source": [
        "# history = model.fit(x_train, y_train,\n",
        "#                     validation_split=0.25, epochs=300,\n",
        "#                     batch_size=200, verbose=1,\n",
        "#                     callbacks=[early_stopping_callback, checkpointer])\n",
        "# print(\"Test Accuracy: %.4f\" % (model.evaluate(x_test, y_test)[1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXPUie8UBUg3"
      },
      "outputs": [],
      "source": [
        "y_loss = history.history[\"loss\"]\n",
        "\n",
        "y_vloss = history.history[\"val_loss\"]\n",
        "\n",
        "num = len(y_loss)\n",
        "plt.figure()\n",
        "plt.plot(range(num), y_loss, marker='o', c='blue', label='Training')\n",
        "plt.plot(range(num), y_vloss, marker='o', c='red', label='Validation')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.grid(True)\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9OCIT3OJdaD"
      },
      "outputs": [],
      "source": [
        "\n",
        "data = np.load(\"/content/drive/MyDrive/DeepLearning/test.npz\")\n",
        "print(data.files)\n",
        "['x']\n",
        "x_pred = data['x']\n",
        "x_pred = x_pred.reshape(x_pred.shape[0], 48,48,1).astype(\"float64\") / 255\n",
        "y_pred = model.predict(x_pred)\n",
        "a = []\n",
        "for i in y_pred :\n",
        "  a.append(i.argmax())\n",
        "\n",
        "\n",
        "with open(\"facial_answer.txt\", \"w\") as f:\n",
        "  for i in a :\n",
        "    data =  \"%d\\n\"%i\n",
        "    f.write(data)\n",
        "len(y_pred)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "12YQF0853Z0MpmtVOBF8tPGN3qdYHQtLj",
      "authorship_tag": "ABX9TyNDxWjyjKDAETBzqT2bTg0/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}